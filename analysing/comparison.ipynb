{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file compares and analyses the IMBI_Marko miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, 'C:/Users/Marko/Desktop/GIt/IMBI_Master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from local_pm4py.algo.analysis import custom_enum\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "from pm4py import view_petri_net\n",
    "from pm4py.algo.evaluation.replay_fitness import algorithm as replay_fitness_evaluator\n",
    "from pm4py import precision_alignments\n",
    "from pm4py import precision_token_based_replay\n",
    "from pm4py import discover_petri_net_heuristics\n",
    "from pm4py.convert import convert_to_petri_net\n",
    "from pm4py.algo.discovery.inductive import algorithm as pm4py_algorithm\n",
    "from pm4py.algo.discovery.inductive.variants import imf as pm4py_imf\n",
    "import pandas as pd\n",
    "from pm4py.algo.discovery.inductive.algorithm import Variants as ind_Variants\n",
    "from local_pm4py.algo.analysis import Optimzation_Goals\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import fpdf\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(a, b):\n",
    "  # try: catch\n",
    "  if math.isclose(a+b,0):\n",
    "    return 0\n",
    "  return 2 * (a * b) / (a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cuts(fileName):\n",
    "  pdf = fpdf.FPDF(format='letter') #pdf format\n",
    "  pdf.add_page() #create new page\n",
    "  pdf.set_font(\"Arial\", size=8) # font and textsize\n",
    "\n",
    "  depth = 0\n",
    "  currentIteration = 1\n",
    "  file_path = \"imbi_cuts/depth_\" + str(depth) + \"_It_\" + str(currentIteration)\n",
    "  \n",
    "  folder_name = \"imbi_cuts\"\n",
    "  # Check if the folder already exists\n",
    "  if not os.path.exists(folder_name):\n",
    "      # Create the folder\n",
    "      os.makedirs(folder_name)\n",
    "    \n",
    "  # for depth\n",
    "  while(os.path.isfile(file_path + \".png\")):\n",
    "    # for iteration\n",
    "    while(os.path.isfile(file_path + \".png\")):\n",
    "      with open(file_path + \".txt\") as f:\n",
    "        pdf.cell(100, 4, txt=\"Cut: \" + str(depth + 1) + \" it: \" + str(currentIteration), ln=1, align=\"C\")\n",
    "        pdf.cell(1000, 4, txt=\"cut | type | cost_p | cost_m | cost_ratio | fitP\", ln=1, align=\"L\")\n",
    "        pdf.cell(1000, 4, txt=\"\", ln=1, align=\"L\")\n",
    "        lines = f.readlines()\n",
    "        readLines = 0\n",
    "        for line in lines:\n",
    "          if readLines == 0:\n",
    "            outputLine = line.replace(\" \", \" | \")\n",
    "          else:\n",
    "            outputLine = line\n",
    "          pdf.cell(1000, 4, txt=outputLine, ln=1, align=\"L\")\n",
    "          readLines += 1\n",
    "          if readLines == 3:\n",
    "            readLines = 0\n",
    "            pdf.cell(1000, 4, txt=\"\", ln=1, align=\"L\")\n",
    "      img = Image.open(file_path + \".png\")\n",
    "      width,height = img.size\n",
    "      # print(width, height)\n",
    "      pdf.image(file_path + \".png\",w=min(150,width/3),h=min(150,height/3))\n",
    "      pdf.add_page()\n",
    "      currentIteration += 1\n",
    "      file_path = \"imbi_cuts/depth_\" + str(depth) + \"_It_\" + str(currentIteration)\n",
    "      \n",
    "    depth += 1\n",
    "    currentIteration = 1\n",
    "    file_path = \"imbi_cuts/depth_\" + str(depth) + \"_It_\" + str(currentIteration)\n",
    "  pdf.output(fileName + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_petriNet(df, miner, logPName, logMName = \"\"):\n",
    "  df_temp = df[df[\"miner\"] == miner]\n",
    "  df_temp = df_temp[df_temp[\"logM_Name\"] == logMName]\n",
    "  df_temp = df_temp[df_temp[\"logP_Name\"] == logPName]\n",
    "  for net, im, fm in zip(df_temp.net, df_temp.im, df_temp.fm):\n",
    "    print(\"Displaying: \" + str(miner) + \" \" + str(logPName) + \" \" + str(logMName))\n",
    "    view_petri_net(net, im, fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_All_petriNet(df, miner):\n",
    "  df_temp = df[df[\"miner\"] == miner]\n",
    "  for logPName, logMName in zip(df_temp.logP_Name, df_temp.logM_Name):\n",
    "    visualize_petriNet(df,miner,logPName,logMName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isRowPresent(df, miner, logPName, logMName, imf_noiseThreshold, hm_dependency_threshold, im_bi_sup, im_bi_ratio):\n",
    "  dftemp = df[df[\"miner\"] == miner]\n",
    "  dftemp = dftemp[dftemp[\"logP_Name\"] == logPName]\n",
    "  dftemp = dftemp[dftemp[\"logM_Name\"] == logMName]\n",
    "  dftemp = dftemp[dftemp[\"imf_noise_thr\"] == imf_noiseThreshold]\n",
    "  dftemp = dftemp[dftemp[\"hm_depen_thr\"] == hm_dependency_threshold]\n",
    "  dftemp = dftemp[dftemp[\"im_bi_sup\"] == im_bi_sup]\n",
    "  dftemp = dftemp[dftemp[\"im_bi_ratio\"] == im_bi_ratio]\n",
    "  if len(dftemp.index) > 0:\n",
    "    return True\n",
    "  return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runDoubleLogEvaluation(df,log,logM, name,net, im, fm, logPName = \"\",logMName = \"\", imf_noiseThreshold = 0, hm_dependency_threshold = 0,im_bi_sup = 0, im_bi_ratio = 0):\n",
    "  mes = Optimzation_Goals.apply_petri(log,logM,net,im,fm)\n",
    "\n",
    "  df = pd.concat([df, pd.DataFrame.from_records([{\n",
    "    \"miner\" : name,\n",
    "    \"logP_Name\": logPName[:logPName.rfind(\".\")],\n",
    "    \"logM_Name\": logMName[:logMName.rfind(\".\")],\n",
    "    \"imf_noise_thr\" : imf_noiseThreshold,\n",
    "    \"hm_depen_thr\" : hm_dependency_threshold,\n",
    "    \"im_bi_sup\" : im_bi_sup,\n",
    "    \"im_bi_ratio\" : im_bi_ratio,\n",
    "    \"acc_logs\": mes['acc'],\n",
    "    \"fitP\" : mes['fitP'],\n",
    "    \"fitM\" : mes['fitM'],\n",
    "    \"f1_fit_logs\": mes['F1'],\n",
    "    \"precP\" : mes['precision'],\n",
    "    \"net\": net,\n",
    "    \"im\" : im,\n",
    "    \"fm\" : fm\n",
    "  }])])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSingleLogEvaluation(df,log,logM, name, net, im, fm, logPName = \"\",logMName = \"\", imf_noiseThreshold = 0, hm_dependency_threshold = 0,im_bi_sup = 0, im_bi_ratio = 0):\n",
    "  \n",
    "  # if isRowPresent(df, name, logPName, logMName, imf_noiseThreshold, hm_dependency_threshold, im_bi_sup, im_bi_ratio) == True:\n",
    "  #   print (\"Skipped because present\")\n",
    "  #   return df\n",
    "  \n",
    "  parameters = {pn_visualizer.Variants.WO_DECORATION.value.Parameters.FORMAT:\"pdf\"}\n",
    "  gviz = pn_visualizer.apply(net, im, fm, parameters=parameters)\n",
    "\n",
    "  try:\n",
    "    fitness_token = replay_fitness_evaluator.apply(log, net, im, fm, variant=replay_fitness_evaluator.Variants.TOKEN_BASED)[\"log_fitness\"]\n",
    "  except:\n",
    "    fitness_token = 0\n",
    "  try:\n",
    "    fitness_align = replay_fitness_evaluator.apply(log, net, im, fm, variant=replay_fitness_evaluator.Variants.ALIGNMENT_BASED)[\"log_fitness\"]\n",
    "  except:\n",
    "    fitness_align = 0\n",
    "    \n",
    "  try:\n",
    "    prec_token = precision_token_based_replay(log, net, im, fm)\n",
    "  except:\n",
    "    prec_token = 0\n",
    "    \n",
    "  try:\n",
    "    prec_alignment = precision_alignments(log, net, im, fm)\n",
    "  except:\n",
    "    prec_alignment = 0\n",
    "    \n",
    "\n",
    "  df = pd.concat([df, pd.DataFrame.from_records([{\n",
    "      \"miner\" : name,\n",
    "      \"logP_Name\": logPName,\n",
    "      \"logM_Name\": logMName,\n",
    "      \"imf_noise_thr\" : imf_noiseThreshold,\n",
    "      \"hm_depen_thr\" : hm_dependency_threshold,\n",
    "      \"im_bi_sup\" : im_bi_sup,\n",
    "      \"im_bi_ratio\" : im_bi_ratio,\n",
    "      \"fit_tok\": fitness_token,\n",
    "      \"fit_alig\": fitness_align,\n",
    "      \"prec_tok\": prec_token,\n",
    "      \"prec_alig\": prec_alignment,\n",
    "      \"f1_tok\": f1_score(fitness_token, prec_token),\n",
    "      \"f1_alig\": f1_score(fitness_align, prec_alignment),\n",
    "      \"net\": net,\n",
    "      \"im\" : im,\n",
    "      \"fm\" : fm\n",
    "  }])])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_Model_To_Database(df,log,logM, name,net, im, fm, logPName = \"\",logMName = \"\", imf_noiseThreshold = 0, hm_dependency_threshold = 0,im_bi_sup = 0, im_bi_ratio = 0):\n",
    "  if logMName == \"\":\n",
    "    df = runSingleLogEvaluation(df,log,logM, name,net, im, fm, logPName,logMName, imf_noiseThreshold, hm_dependency_threshold,im_bi_sup, im_bi_ratio)\n",
    "  else:\n",
    "    df = runDoubleLogEvaluation(df,log,logM, name,net, im, fm, logPName,logMName, imf_noiseThreshold, hm_dependency_threshold,im_bi_sup, im_bi_ratio)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getF1Value(df, miner, logPName, logMName, support, ratio):\n",
    "  dftemp = df[df[\"miner\"] == miner]\n",
    "  dftemp = dftemp[dftemp[\"logP_Name\"] == logPName[:logPName.rfind(\".\")]]\n",
    "  dftemp = dftemp[dftemp[\"logM_Name\"] == logMName[:logPName.rfind(\".\")]]\n",
    "  dftemp = dftemp[dftemp[\"im_bi_sup\"] == support]\n",
    "  dftemp = dftemp[dftemp[\"im_bi_ratio\"] == ratio]\n",
    "  if len(dftemp.index) > 1:\n",
    "    raise Exception(\"Error, too many rows.\")\n",
    "  return dftemp[\"f1_fit_logs\"].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyMinerToLog(df, logPathP, logPathM,logPName, logMName = \"\", noiseThreshold = 0.0, dependency_threshold=0.0, support = 0, ratio = 0):\n",
    "  logP = xes_importer.apply(logPathP)\n",
    "  if logMName == \"\":\n",
    "    logM = logP\n",
    "    # inductive miner\n",
    "    print(\"Running IM\")\n",
    "    pt = pm4py_algorithm.apply(logP,variant=ind_Variants.IM)\n",
    "    net, im, fm = convert_to_petri_net(pt)\n",
    "    df = add_Model_To_Database(df=df, log=logP, logM=logM,net=net,im=im,fm=fm,name=\"IM\",logPName=logPName, im_bi_sup=support,im_bi_ratio=ratio)\n",
    "    \n",
    "    #imf \n",
    "    print(\"Running IMF\")\n",
    "    parameters = {pm4py_imf.IMFParameters.NOISE_THRESHOLD : noiseThreshold}\n",
    "    pt = pm4py_algorithm.apply(logP,variant=ind_Variants.IMf, parameters=parameters)\n",
    "    net, im, fm = convert_to_petri_net(pt)\n",
    "    df = add_Model_To_Database(df=df, log=logP, logM=logM,net=net,im=im,fm=fm,name=\"IMF\",logPName=logPName,imf_noiseThreshold=noiseThreshold, im_bi_sup=support,im_bi_ratio=ratio)\n",
    "    \n",
    "    #hm\n",
    "    print(\"Running HM\")\n",
    "    net, im, fm = discover_petri_net_heuristics(logP,dependency_threshold=dependency_threshold)\n",
    "    df = add_Model_To_Database(df=df, log=logP, logM=logM,net=net,im=im,fm=fm,name=\"HM\",logPName=logPName,hm_dependency_threshold=dependency_threshold, im_bi_sup=support,im_bi_ratio=ratio)\n",
    "  else:\n",
    "    logM = xes_importer.apply(logPathM)\n",
    "    \n",
    "  # imbi_ali\n",
    "  print(\"Running IMbi_ali\")\n",
    "  cost_Variant = custom_enum.Cost_Variant.ACTIVITY_FREQUENCY_SCORE\n",
    "  net, im, fm = inductive_miner.apply_bi(logP,logM, variant=inductive_miner.Variants.IMbi, sup=support, ratio=ratio, size_par=len(logP)/len(logM), cost_Variant=cost_Variant)\n",
    "  df = add_Model_To_Database(df=df,log=logP, logM=logM,net=net,im=im,fm=fm,name=\"IMbi_ali\",logPName=logPName, logMName=logMName,im_bi_sup=support,im_bi_ratio=ratio)\n",
    "  \n",
    "  fileName_cuts_ali = \"cuts_IMbi_ali_sup_\" + str(support) + \"_ratio_\" + str(ratio) + \"_logP_\" + logPName[:logPName.rfind(\".\")] + \"_logM_\" + logMName[:logMName.rfind(\".\")]\n",
    "  visualize_cuts(fileName_cuts_ali)\n",
    "  \n",
    "  for f in os.listdir(\"imbi_cuts\"):\n",
    "    os.remove(os.path.join(\"imbi_cuts\", f))\n",
    "  \n",
    "  #imbi_mar\n",
    "  print(\"Running IMbi_mar\")\n",
    "  cost_Variant = custom_enum.Cost_Variant.ACTIVITY_RELATION_SCORE\n",
    "  net, im, fm = inductive_miner.apply_bi(logP,logM, variant=inductive_miner.Variants.IMbi, sup=support, ratio=ratio, size_par=len(logP)/len(logM), cost_Variant=cost_Variant)\n",
    "  df = add_Model_To_Database(df=df, log=logP, logM=logM,net=net,im=im,fm=fm,name=\"IMbi_mar\",logPName=logPName, logMName=logMName, im_bi_sup=support,im_bi_ratio=ratio)\n",
    "  \n",
    "  fileName_cuts_mar = \"cuts_IMbi_mar_sup_\" + str(support) + \"_ratio_\" + str(ratio) + \"_logP-\" + logPName[:logPName.rfind(\".\")] + \"_logM-\" + logMName[:logMName.rfind(\".\")]\n",
    "  visualize_cuts(fileName_cuts_mar)\n",
    "  \n",
    "  for f in os.listdir(\"imbi_cuts\"):\n",
    "    os.remove(os.path.join(\"imbi_cuts\", f))\n",
    "  \n",
    "  # for double log\n",
    "  marImproved = False\n",
    "  if logMName != \"\":\n",
    "    f1_ali = getF1Value(df,\"IMbi_ali\",logPName,logMName,support,ratio)\n",
    "    f1_mar = getF1Value(df,\"IMbi_mar\",logPName,logMName,support,ratio)\n",
    "    if f1_ali < f1_mar:\n",
    "      display(\"Mar > Ali\")\n",
    "      marImproved = True\n",
    "      if True:\n",
    "        if os.path.exists(fileName_cuts_ali+ \".pdf\"):\n",
    "          os.remove(fileName_cuts_ali+ \".pdf\")\n",
    "        if os.path.exists(fileName_cuts_mar+ \".pdf\"):\n",
    "          os.remove(fileName_cuts_mar + \".pdf\")\n",
    "    else:\n",
    "      display(\"Ali > Mar\")\n",
    "  return df, marImproved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"miner\", \"logP_Name\", \"logM_Name\",\"imf_noise_thr\",\"hm_depen_thr\",\"im_bi_sup\",\"im_bi_ratio\", \"fit_tok\", \"fit_alig\", \"prec_tok\", \"prec_alig\", \"f1_tok\", \"f1_alig\", \"net\", \"im\", \"fm\"]\n",
    "df = pd.DataFrame(data=None, index=None, columns=columns, dtype=None, copy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = \"C:/Users/Marko/Desktop/IMbi_Data/analysing/\"\n",
    "\n",
    "lpNames = [\"lp_2012.xes\", \"lp_2017.xes\", \"lp_2018.xes\"]\n",
    "# lpNames = [\"lp_2012.xes\"]\n",
    "\n",
    "lMNames = [\"lm_2012.xes\", \"lm_2017.xes\", \"lm_2018.xes\"]\n",
    "# lMNames = [\"lm_2012.xes\"]\n",
    "lpPaths = []\n",
    "lmPaths = []\n",
    "\n",
    "for lp in lpNames:\n",
    "  lpPaths.append((lp,rootPath + lp))\n",
    "for lm in lMNames:\n",
    "  lmPaths.append((lm,rootPath + lm))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running: lp_2012.xes 1/12'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'i: 0 ratio: 0 sup: 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 10556/10556 [00:01<00:00, 9033.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed variants :: 100%|██████████| 25/25 [00:00<00:00, 1428.54it/s]\n",
      "aligning log, completed variants :: 100%|██████████| 25/25 [00:00<00:00, 370.46it/s]\n",
      "c:\\Users\\Marko\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pm4py\\utils.py:486: UserWarning: the EventLog class has been deprecated and will be removed in a future release.\n",
      "  warnings.warn(\"the EventLog class has been deprecated and will be removed in a future release.\")\n",
      "replaying log with TBR, completed variants :: 100%|██████████| 43/43 [00:00<00:00, 1563.63it/s]\n",
      "computing precision with alignments, completed variants :: 100%|██████████| 43/43 [00:00<00:00, 803.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IMF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed variants :: 100%|██████████| 25/25 [00:00<00:00, 1612.82it/s]\n",
      "aligning log, completed variants :: 100%|██████████| 25/25 [00:00<00:00, 387.60it/s]\n",
      "replaying log with TBR, completed variants :: 100%|██████████| 43/43 [00:00<00:00, 1686.22it/s]\n",
      "computing precision with alignments, completed variants :: 100%|██████████| 43/43 [00:00<00:00, 834.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replaying log with TBR, completed variants :: 100%|██████████| 25/25 [00:00<00:00, 1428.64it/s]\n",
      "aligning log, completed variants :: 100%|██████████| 25/25 [00:00<00:00, 354.62it/s]\n",
      "replaying log with TBR, completed variants :: 100%|██████████| 43/43 [00:00<00:00, 2529.60it/s]\n",
      "computing precision with alignments, completed variants :: 100%|██████████| 43/43 [00:00<00:00, 860.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IMbi_ali\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m display(\u001b[39m\"\u001b[39m\u001b[39mRunning: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m lpPaths[i][\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(runs) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(totalRuns))\n\u001b[0;32m     13\u001b[0m display(\u001b[39m\"\u001b[39m\u001b[39mi: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m ratio: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(ratio) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m sup: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(sup))\n\u001b[1;32m---> 14\u001b[0m df, marImproved \u001b[39m=\u001b[39m applyMinerToLog(df, lpPaths[i][\u001b[39m1\u001b[39;49m], \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m, lpPaths[i][\u001b[39m0\u001b[39;49m],\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0.2\u001b[39;49m, \u001b[39m0.99\u001b[39;49m, sup, ratio)\n\u001b[0;32m     15\u001b[0m runs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[27], line 28\u001b[0m, in \u001b[0;36mapplyMinerToLog\u001b[1;34m(df, logPathP, logPathM, logPName, logMName, noiseThreshold, dependency_threshold, support, ratio)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRunning IMbi_ali\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m cost_Variant \u001b[39m=\u001b[39m custom_enum\u001b[39m.\u001b[39mCost_Variant\u001b[39m.\u001b[39mACTIVITY_FREQUENCY_SCORE\n\u001b[1;32m---> 28\u001b[0m net, im, fm \u001b[39m=\u001b[39m inductive_miner\u001b[39m.\u001b[39;49mapply_bi(logP,logM, variant\u001b[39m=\u001b[39;49minductive_miner\u001b[39m.\u001b[39;49mVariants\u001b[39m.\u001b[39;49mIMbi, sup\u001b[39m=\u001b[39;49msupport, ratio\u001b[39m=\u001b[39;49mratio, size_par\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(logP)\u001b[39m/\u001b[39;49m\u001b[39mlen\u001b[39;49m(logM), cost_Variant\u001b[39m=\u001b[39;49mcost_Variant)\n\u001b[0;32m     29\u001b[0m df \u001b[39m=\u001b[39m add_Model_To_Database(df\u001b[39m=\u001b[39mdf,log\u001b[39m=\u001b[39mlogP, logM\u001b[39m=\u001b[39mlogM,net\u001b[39m=\u001b[39mnet,im\u001b[39m=\u001b[39mim,fm\u001b[39m=\u001b[39mfm,name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIMbi_ali\u001b[39m\u001b[39m\"\u001b[39m,logPName\u001b[39m=\u001b[39mlogPName, logMName\u001b[39m=\u001b[39mlogMName,im_bi_sup\u001b[39m=\u001b[39msupport,im_bi_ratio\u001b[39m=\u001b[39mratio)\n\u001b[0;32m     31\u001b[0m fileName_cuts_ali \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuts_IMbi_ali_sup_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(support) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_ratio_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(ratio) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_logP_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m logPName[:logPName\u001b[39m.\u001b[39mrfind(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_logM_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m logMName[:logMName\u001b[39m.\u001b[39mrfind(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)]\n",
      "File \u001b[1;32mC:/Users/Marko/Desktop/GIt/IMBI_Master\\local_pm4py\\algo\\discovery\\inductive\\algorithm.py:76\u001b[0m, in \u001b[0;36mapply_bi\u001b[1;34m(logp, logm, parameters, variant, sup, ratio, size_par, cost_Variant)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_bi\u001b[39m(logp: Union[EventLog, EventStream, pd\u001b[39m.\u001b[39mDataFrame], logm: Union[EventLog, EventStream, pd\u001b[39m.\u001b[39mDataFrame], parameters: Optional[Dict[Any, Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, variant\u001b[39m=\u001b[39mDEFAULT_VARIANT_LOG, sup\u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, ratio \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, size_par \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, cost_Variant \u001b[39m=\u001b[39m custom_enum\u001b[39m.\u001b[39mCost_Variant\u001b[39m.\u001b[39mACTIVITY_FREQUENCY_SCORE) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[PetriNet, Marking, Marking]:\n\u001b[0;32m     52\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39m    Apply the chosen IM algorithm to a log obtaining a Petri net along with an initial and final marking\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39m        Final marking\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m exec_utils\u001b[39m.\u001b[39;49mget_variant(variant)\u001b[39m.\u001b[39;49mapply(logp,logm, parameters\u001b[39m=\u001b[39;49mparameters, sup\u001b[39m=\u001b[39;49m sup, ratio \u001b[39m=\u001b[39;49m ratio, size_par \u001b[39m=\u001b[39;49m size_par, cost_Variant\u001b[39m=\u001b[39;49mcost_Variant)\n",
      "File \u001b[1;32mC:/Users/Marko/Desktop/GIt/IMBI_Master\\local_pm4py\\algo\\discovery\\inductive\\variants\\im_bi\\algorithm.py:82\u001b[0m, in \u001b[0;36mapply\u001b[1;34m(logp, logm, parameters, sup, ratio, size_par, cost_Variant)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpm4py\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstatistics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvariants\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m get \u001b[39mas\u001b[39;00m variants_get\n\u001b[1;32m---> 82\u001b[0m net, initial_marking, final_marking \u001b[39m=\u001b[39m tree_to_petri\u001b[39m.\u001b[39mapply(apply_tree(logp,logm, parameters,sup\u001b[39m=\u001b[39;49m sup, ratio \u001b[39m=\u001b[39;49m ratio, size_par \u001b[39m=\u001b[39;49m size_par, cost_Variant\u001b[39m=\u001b[39;49mcost_Variant))\n\u001b[0;32m     83\u001b[0m \u001b[39mreturn\u001b[39;00m net, initial_marking, final_marking\n",
      "File \u001b[1;32mc:\\Users\\Marko\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\deprecation.py:260\u001b[0m, in \u001b[0;36mdeprecated.<locals>._function_wrapper.<locals>._inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m     the_warning \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(function\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, deprecated_in,\n\u001b[0;32m    256\u001b[0m                       removed_in, details)\n\u001b[0;32m    257\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(the_warning, category\u001b[39m=\u001b[39m\u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m                   stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m--> 260\u001b[0m \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mC:/Users/Marko/Desktop/GIt/IMBI_Master\\local_pm4py\\algo\\discovery\\inductive\\variants\\im_bi\\algorithm.py:162\u001b[0m, in \u001b[0;36mapply_tree\u001b[1;34m(logp, logm, parameters, sup, ratio, size_par, cost_Variant)\u001b[0m\n\u001b[0;32m    159\u001b[0m     contains_empty_traces \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m([\u001b[39mlen\u001b[39m(trace) \u001b[39mfor\u001b[39;00m trace \u001b[39min\u001b[39;00m logp]) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    161\u001b[0m recursion_depth \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 162\u001b[0m sub \u001b[39m=\u001b[39m subtree\u001b[39m.\u001b[39;49mmake_tree(logp,logm, dfgp, dfgp, dfgp, activitiesp, c, recursion_depth, \u001b[39m0.0\u001b[39;49m, start_activitiesp,\n\u001b[0;32m    163\u001b[0m                         end_activitiesp,\n\u001b[0;32m    164\u001b[0m                         start_activitiesp, end_activitiesp, parameters, sup\u001b[39m=\u001b[39;49m sup, ratio \u001b[39m=\u001b[39;49m ratio, size_par \u001b[39m=\u001b[39;49m size_par, cost_Variant\u001b[39m=\u001b[39;49mcost_Variant)\n\u001b[0;32m    166\u001b[0m process_tree \u001b[39m=\u001b[39m get_tree_repr_implain\u001b[39m.\u001b[39mget_repr(sub, \u001b[39m0\u001b[39m, contains_empty_traces\u001b[39m=\u001b[39mcontains_empty_traces)\n\u001b[0;32m    167\u001b[0m \u001b[39m# Ensures consistency to the parent pointers in the process tree\u001b[39;00m\n",
      "File \u001b[1;32mC:/Users/Marko/Desktop/GIt/IMBI_Master\\local_pm4py\\algo\\discovery\\inductive\\variants\\im_bi\\data_structures\\subtree_plain.py:635\u001b[0m, in \u001b[0;36mmake_tree\u001b[1;34m(logp, logm, dfg, master_dfg, initial_dfg, activities, c, recursion_depth, noise_threshold, start_activities, end_activities, initial_start_activities, initial_end_activities, parameters, sup, ratio, size_par, cost_Variant)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_tree\u001b[39m(logp, logm, dfg, master_dfg, initial_dfg, activities, c, recursion_depth, noise_threshold, start_activities,\n\u001b[0;32m    633\u001b[0m               end_activities, initial_start_activities, initial_end_activities, parameters\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sup\u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, ratio \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, size_par \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, cost_Variant \u001b[39m=\u001b[39m custom_enum\u001b[39m.\u001b[39mCost_Variant\u001b[39m.\u001b[39mACTIVITY_FREQUENCY_SCORE):\n\u001b[1;32m--> 635\u001b[0m     tree \u001b[39m=\u001b[39m SubtreePlain(logp,logm, dfg, master_dfg, initial_dfg, activities, c, recursion_depth, noise_threshold,\n\u001b[0;32m    636\u001b[0m                         start_activities,\n\u001b[0;32m    637\u001b[0m                         end_activities, initial_start_activities, initial_end_activities, parameters\u001b[39m=\u001b[39;49mparameters, sup\u001b[39m=\u001b[39;49m sup, ratio \u001b[39m=\u001b[39;49m ratio, size_par \u001b[39m=\u001b[39;49m size_par, cost_Variant\u001b[39m=\u001b[39;49mcost_Variant)\n\u001b[0;32m    639\u001b[0m     \u001b[39mreturn\u001b[39;00m tree\n",
      "File \u001b[1;32mC:/Users/Marko/Desktop/GIt/IMBI_Master\\local_pm4py\\algo\\discovery\\inductive\\variants\\im_bi\\data_structures\\subtree_plain.py:200\u001b[0m, in \u001b[0;36mSubtreePlain.__init__\u001b[1;34m(self, logp, logm, dfg, master_dfg, initial_dfg, activities, counts, rec_depth, noise_threshold, start_activities, end_activities, initial_start_activities, initial_end_activities, parameters, real_init, sup, ratio, size_par, cost_Variant)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_log \u001b[39m=\u001b[39m logp\n\u001b[0;32m    198\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivities \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitialize_tree(dfg, logp, logm, initial_dfg, activities, parameters \u001b[39m=\u001b[39;49m parameters, sup \u001b[39m=\u001b[39;49m sup, ratio \u001b[39m=\u001b[39;49m ratio, size_par \u001b[39m=\u001b[39;49m size_par, cost_Variant \u001b[39m=\u001b[39;49m cost_Variant)\n",
      "File \u001b[1;32mC:/Users/Marko/Desktop/GIt/IMBI_Master\\local_pm4py\\algo\\discovery\\inductive\\variants\\im_bi\\data_structures\\subtree_plain.py:219\u001b[0m, in \u001b[0;36mSubtreePlain.initialize_tree\u001b[1;34m(self, dfg, logp, logm, initial_dfg, activities, second_iteration, end_call, parameters, sup, ratio, size_par, cost_Variant)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_log \u001b[39m=\u001b[39m logp\n\u001b[0;32m    217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters \u001b[39m=\u001b[39m parameters\n\u001b[1;32m--> 219\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdetect_cut(second_iteration\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, parameters\u001b[39m=\u001b[39;49mparameters, sup\u001b[39m=\u001b[39;49m sup, ratio \u001b[39m=\u001b[39;49m ratio, size_par \u001b[39m=\u001b[39;49m size_par, cost_Variant \u001b[39m=\u001b[39;49m cost_Variant)\n",
      "File \u001b[1;32mC:/Users/Marko/Desktop/GIt/IMBI_Master\\local_pm4py\\algo\\discovery\\inductive\\variants\\im_bi\\data_structures\\subtree_plain.py:489\u001b[0m, in \u001b[0;36mSubtreePlain.detect_cut\u001b[1;34m(self, second_iteration, parameters, sup, ratio, size_par, cost_Variant)\u001b[0m\n\u001b[0;32m    484\u001b[0m         start_activities \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m    485\u001b[0m             start_activities_get\u001b[39m.\u001b[39mget_start_activities(l[\u001b[39m0\u001b[39m], parameters\u001b[39m=\u001b[39mparameters)\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m    486\u001b[0m         end_activities \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m    487\u001b[0m             end_activities_get\u001b[39m.\u001b[39mget_end_activities(l[\u001b[39m0\u001b[39m], parameters\u001b[39m=\u001b[39mparameters)\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m    488\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren\u001b[39m.\u001b[39mappend(\n\u001b[1;32m--> 489\u001b[0m             SubtreePlain(l[\u001b[39m0\u001b[39;49m],l[\u001b[39m1\u001b[39;49m], new_dfg, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmaster_dfg, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitial_dfg, activities, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcounts,\n\u001b[0;32m    490\u001b[0m                          \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrec_depth \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m    491\u001b[0m                          noise_threshold\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnoise_threshold, start_activities\u001b[39m=\u001b[39;49mstart_activities,\n\u001b[0;32m    492\u001b[0m                          end_activities\u001b[39m=\u001b[39;49mend_activities,\n\u001b[0;32m    493\u001b[0m                          initial_start_activities\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitial_start_activities,\n\u001b[0;32m    494\u001b[0m                          initial_end_activities\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitial_end_activities,\n\u001b[0;32m    495\u001b[0m                          parameters\u001b[39m=\u001b[39;49mparameters, sup\u001b[39m=\u001b[39;49m sup, ratio \u001b[39m=\u001b[39;49m input_ratio, size_par \u001b[39m=\u001b[39;49m size_par, cost_Variant\u001b[39m=\u001b[39;49mcost_Variant))\n\u001b[0;32m    496\u001b[0m \u001b[39melif\u001b[39;00m (cut[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mexc\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m (cut[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mexc2\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    497\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetected_cut \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mconcurrent\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mC:/Users/Marko/Desktop/GIt/IMBI_Master\\local_pm4py\\algo\\discovery\\inductive\\variants\\im_bi\\data_structures\\subtree_plain.py:181\u001b[0m, in \u001b[0;36mSubtreePlain.__init__\u001b[1;34m(self, logp, logm, dfg, master_dfg, initial_dfg, activities, counts, rec_depth, noise_threshold, start_activities, end_activities, initial_start_activities, initial_end_activities, parameters, real_init, sup, ratio, size_par, cost_Variant)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_depth \u001b[39m=\u001b[39m rec_depth\n\u001b[0;32m    180\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnoise_threshold \u001b[39m=\u001b[39m noise_threshold\n\u001b[1;32m--> 181\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_activities \u001b[39m=\u001b[39m start_activities_filter\u001b[39m.\u001b[39;49mget_start_activities(logp)\n\u001b[0;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_activitiesM \u001b[39m=\u001b[39m start_activities_filter\u001b[39m.\u001b[39mget_start_activities(logm)\n\u001b[0;32m    183\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend_activities \u001b[39m=\u001b[39m end_activities_filter\u001b[39m.\u001b[39mget_end_activities(logp)\n",
      "File \u001b[1;32mc:\\Users\\Marko\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pm4py\\statistics\\start_activities\\log\\get.py:63\u001b[0m, in \u001b[0;36mget_start_activities\u001b[1;34m(log, parameters)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mfor\u001b[39;00m trace \u001b[39min\u001b[39;00m log:\n\u001b[0;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trace) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[39mif\u001b[39;00m attribute_key \u001b[39min\u001b[39;49;00m trace[\u001b[39m0\u001b[39;49m]:\n\u001b[0;32m     64\u001b[0m             activity_first_event \u001b[39m=\u001b[39m trace[\u001b[39m0\u001b[39m][attribute_key]\n\u001b[0;32m     65\u001b[0m             \u001b[39mif\u001b[39;00m activity_first_event \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m start_activities:\n",
      "File \u001b[1;32mc:\\Users\\Marko\\AppData\\Local\\Programs\\Python\\Python38\\lib\\_collections_abc.py:665\u001b[0m, in \u001b[0;36mMapping.__contains__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__contains__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m--> 665\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    666\u001b[0m         \u001b[39mself\u001b[39m[key]\n\u001b[0;32m    667\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runSingleLog = True\n",
    "\n",
    "ratios = [0]\n",
    "sups = [0, 0.2, 0.3, 0.5]\n",
    "\n",
    "runs = 1\n",
    "totalRuns = len(lpPaths) * len(ratios) * len(sups)\n",
    "if runSingleLog:\n",
    "  for i in range(0,len(lpPaths)):\n",
    "    for ratio in ratios:\n",
    "      for sup in sups:\n",
    "        display(\"Running: \" + lpPaths[i][0] + \" \" + str(runs) + \"/\" + str(totalRuns))\n",
    "        display(\"i: \" + str(i) + \" ratio: \" + str(ratio) + \" sup: \" + str(sup))\n",
    "        df, marImproved = applyMinerToLog(df, lpPaths[i][1], \"\", lpPaths[i][0],\"\", 0.2, 0.99, sup, ratio)\n",
    "        runs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runSingleLog == False:\n",
    "  runs = 1\n",
    "  improving_runs = 0\n",
    "  \n",
    "  ratios = [1, 0.8]\n",
    "  sups = [0.2, 0.3]\n",
    "  \n",
    "  totalRuns = len(lpPaths) * len(ratios) * len(sups)\n",
    "\n",
    "  for i in range(0,len(lpPaths)):\n",
    "    for ratio in ratios:\n",
    "      for sup in sups:\n",
    "        display(\"Running: \" + lpPaths[i][0] + \" \" + str(runs) + \"/\" + str(totalRuns))\n",
    "        display(\"i: \" + str(i) + \" ratio: \" + str(ratio) + \" sup: \" + str(sup))\n",
    "        display(\"Stats: \" + str(improving_runs) + \"/\" + str(runs))\n",
    "        df, marImproved = applyMinerToLog(df, lpPaths[i][1], lmPaths[i][1], lpPaths[i][0],lmPaths[i][0], 0.2, 0.99, sup, ratio)\n",
    "        if marImproved:\n",
    "          improving_runs += 1\n",
    "        runs += 1\n",
    "  \n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setupYTickList(minValue, step):\n",
    "  res = []\n",
    "  cur = 1\n",
    "  while cur > minValue:\n",
    "    res.append(cur)\n",
    "    cur -= step\n",
    "  res.append(cur)\n",
    "  return res\n",
    "    \n",
    "\n",
    "def displayDoubleLog(df, saveFig = False):\n",
    "  df_grouped = df.groupby(by=[\"logP_Name\",\t\"logM_Name\", \"im_bi_sup\", \"im_bi_ratio\"], group_keys=True).apply(lambda x : x)\n",
    "  \n",
    "  numberOfPlotPerRow = 4\n",
    "  rows = math.ceil(float(len(df_grouped.index.unique()))/numberOfPlotPerRow)\n",
    "  cols = min(len(df_grouped.index.unique()),numberOfPlotPerRow)\n",
    "\n",
    "  fig, axs = plt.subplots(rows, cols, figsize=(15 * (cols / numberOfPlotPerRow), 4 * rows), squeeze=False)\n",
    "  fig.tight_layout(pad=10.0)\n",
    "  cur_Row = 0\n",
    "  cur_Col = 0\n",
    "  for logGroup in df_grouped.index.unique():\n",
    "    df_log_grouped = df_grouped.loc[logGroup]\n",
    "    axs[cur_Row,cur_Col].set_title(\"LogP: \" + logGroup[0] + \" LogM: \" + logGroup[1] + \"\\n\" + \"Sup: \" + str(df_log_grouped.im_bi_sup[0]) + \" ratio: \" + str(df_log_grouped.im_bi_ratio[0]))\n",
    "    axs[cur_Row,cur_Col].set_xlabel(\"Miners\")\n",
    "    j = 0\n",
    "    xTickLabel = []\n",
    "    idx = []\n",
    "    minValue = 0\n",
    "    for miner, acc, fitP, fitM, f1_fit in zip(df_log_grouped.miner, df_log_grouped.acc_logs, df_log_grouped.fitP, df_log_grouped.fitM, df_log_grouped.f1_fit_logs):\n",
    "      minValue = min([minValue, acc, fitP, fitM, f1_fit])\n",
    "      axs[cur_Row,cur_Col].bar(j,acc, color=\"r\", label=\"acc\")\n",
    "      axs[cur_Row,cur_Col].bar(j+1,fitP, color=\"g\", label=\"fitP\")\n",
    "      axs[cur_Row,cur_Col].bar(j+2,fitM, color=\"b\", label=\"fitM\")\n",
    "      axs[cur_Row,cur_Col].bar(j+3,f1_fit, color=\"orange\", label=\"f1_fit\")\n",
    "      xTickLabel.append(miner)\n",
    "      idx.append(j + 1.5)\n",
    "      j += 5\n",
    "      \n",
    "    \n",
    "    axs[cur_Row,cur_Col].set_yticks(setupYTickList(minValue, 0.25))\n",
    "    axs[cur_Row,cur_Col].set_xticks(idx)\n",
    "    axs[cur_Row,cur_Col].set_xticklabels(xTickLabel)\n",
    "    axs[cur_Row,cur_Col].legend(loc='center left', ncols=1, labels=[\"acc\", \"fitP\", \"fitM\", \"f1_fit\"], bbox_to_anchor=(1, 0.5))\n",
    "    cur_Col += 1\n",
    "    \n",
    "    if cur_Col == numberOfPlotPerRow:\n",
    "      cur_Row += 1\n",
    "      cur_Col = 0\n",
    "      \n",
    "  plt.show()\n",
    "\n",
    "  if saveFig:\n",
    "    fig.savefig(\"plot\" + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaySingleLog(df, saveFig = False):\n",
    "  df_grouped = df.groupby(by=[\"logP_Name\",\t\"logM_Name\", \"im_bi_sup\"], group_keys=True).apply(lambda x : x)\n",
    "\n",
    "  numberOfPlotPerRow = 3\n",
    "  rows = math.ceil(float(len(df_grouped.index.unique()))/numberOfPlotPerRow)\n",
    "  cols = min(len(df_grouped.index.unique()),numberOfPlotPerRow)\n",
    "  \n",
    "\n",
    "  for f1_measure in [\"f1_tok\", \"f1_alig\"]:\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(15 * (cols / numberOfPlotPerRow), 4 * rows), squeeze=False)\n",
    "    fig.tight_layout(pad=10.0)\n",
    "    cur_Row = 0\n",
    "    cur_Col = 0\n",
    "    for logGroup in df_grouped.index.unique():\n",
    "      df_log_grouped = df_grouped.loc[logGroup]\n",
    "      axs[cur_Row,cur_Col].set_title(\"LogP: \" + logGroup[0] + \" LogM: \" + logGroup[1] + \"\\n\" + \"Sup: \" + str(df_log_grouped.im_bi_sup[0]))\n",
    "      axs[cur_Row,cur_Col].set_ylabel(f1_measure)\n",
    "      axs[cur_Row,cur_Col].set_xlabel(\"Miners\")\n",
    "      j = 0\n",
    "      xTickLabel = []\n",
    "      idx = []\n",
    "      for miner, f1_tok in zip(df_log_grouped.miner, df_log_grouped[f1_measure]):\n",
    "        axs[cur_Row,cur_Col].bar(j,f1_tok, label=str(miner))\n",
    "        xTickLabel.append(miner)\n",
    "        idx.append(j)\n",
    "        j += 1\n",
    "      axs[cur_Row,cur_Col].set_xticks(idx)\n",
    "      axs[cur_Row,cur_Col].set_xticklabels(xTickLabel, rotation=90)\n",
    "      cur_Col += 1\n",
    "      if cur_Col == numberOfPlotPerRow:\n",
    "        cur_Row += 1\n",
    "        cur_Col = 0\n",
    "        \n",
    "    plt.show()\n",
    "    if saveFig:\n",
    "      fig.savefig(\"plot_\" + f1_measure + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runSingleLog == False:\n",
    "  displayDoubleLog(df)\n",
    "else:\n",
    "  displaySingleLog(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "  if runSingleLog == False:\n",
    "    visualize_petriNet(df, \"IM\", \"lp_2012.xes\", \"\")\n",
    "    visualize_petriNet(df, \"IMbi_mar\", \"lp_2012\", \"lm_2012\")\n",
    "    visualize_petriNet(df, \"IMbi_ali\", \"lp_2012\", \"lm_2012\")\n",
    "  else:\n",
    "    visualize_petriNet(df, \"IM\", \"lp_2012.xes\", \"\")\n",
    "    visualize_petriNet(df, \"IMbi_mar\", \"lp_2012.xes\", \"\")\n",
    "    visualize_petriNet(df, \"IMbi_ali\", \"lp_2012.xes\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "  display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pm4py.objects.petri_net.exporter import exporter as pnml_exporter\n",
    "\n",
    "net, im, fm = df.iloc[4].net, df.iloc[4].im, df.iloc[4].fm\n",
    "view_petri_net(net, im, fm)\n",
    "pnml_exporter.apply(net, im, \"petri_IMbi.pnml\", final_marking=fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
